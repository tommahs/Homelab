---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-agent
  annotations:
    prometheus.io/scrape: "false"
spec:
  mode: daemonset
  image: otel/opentelemetry-collector-contrib:latest
  serviceAccount: otel-collector
  tolerations:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
    operator: Exists
  - effect: NoSchedule
    key: node-role.kubernetes.io/control-plane
    operator: Exists
  env:
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName
  config:
    receivers:
      hostmetrics: # causes the issue with /etc/passwd and /etc/group
        collection_interval: 15s
        scrapers:
          cpu: {}
          disk: {}
          load: {}
          filesystem: {}
          memory: {}
          network: {}
          paging: {}
          processes: {}
          process: {}
          system: {}

      kubeletstats:
        collection_interval: 15s
        auth_type: serviceAccount
        endpoint: ${env:K8S_NODE_NAME}:10250
        insecure_skip_verify: true
      prometheus:
        config:
          scrape_configs:
          - job_name: 'kubernetes-pods'
            kubernetes_sd_configs:
            - role: pod
              namespaces:
                names:
                  - observability
            relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              regex: "true"
              action: keep
            - source_labels: [__meta_kubernetes_pod_label_app]
              regex: grafana|loki|mimir|otel-agent|otel-gateway|promtail|tempo
              action: keep
          - job_name: 'kubernetes-node-metrics'
            scrape_interval: 15s
            scheme: https
            kubernetes_sd_configs:
              - role: node
            bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
            tls_config:
              ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
              insecure_skip_verify: true
            relabel_configs:
              - action: labelmap
                regex: __meta_kubernetes_node_label_(.+)
              - target_label: __address__
                replacement: kubernetes.default.svc:443
              - source_labels: [__meta_kubernetes_node_name]
                regex: (.+)
                target_label: __metrics_path__
                replacement: /api/v1/nodes/$1/proxy/metrics
    processors:
      batch:
        timeout: 10s
      memory_limiter:
        check_interval: 5s
        limit_mib: 1000
      resourcedetection:
        detectors: [env, system]
        system:
          hostname_sources: [os]
      k8sattributes:
        auth_type: "serviceAccount"
        passthrough: false
        filter:
          # only retrieve pods running on the same node as the collector
          node_from_env_var: KUBE_NODE_NAME
        extract:
          # The attributes provided in 'metadata' will be added to associated resources
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
          labels:
            # This label extraction rule takes the value 'app.kubernetes.io/component' label and maps it to the 'app.label.component' attribute which will be added to the associated resources
            - tag_name: app.label.component
              key: app.kubernetes.io/component
              from: pod
        pod_association:
          - sources:
              # This rule associates all resources containing the 'k8s.pod.ip' attribute with the matching pods. If this attribute is not present in the resource, this rule will not be able to find the matching pod.
              - from: resource_attribute
                name: k8s.pod.ip
          - sources:
              # This rule associates all resources containing the 'k8s.pod.uid' attribute with the matching pods. If this attribute is not present in the resource, this rule will not be able to find the matching pod.
              - from: resource_attribute
                name: k8s.pod.uid
          - sources:
              # This rule will use the IP from the incoming connection from which the resource is received, and find the matching pod, based on the 'pod.status.podIP' of the observed pods
              - from: connection

    exporters:
      otlp:
        endpoint: otel-gateway-collector:4317
        tls:
          insecure: true

    service:
      pipelines:
        metrics:
          receivers: [hostmetrics, kubeletstats, prometheus]
          processors: [batch, memory_limiter, resourcedetection, k8sattributes]
          exporters: [otlp]
